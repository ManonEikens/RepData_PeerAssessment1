cacheSolve(a)
b <- makeCacheMatrix(matrix(c(1,2,12,13), 2, 2))
cacheSolve(b)
cacheSolve(b)
library(datasets)
data(iris)
?iris
summary(iris)
View(iris)
lapply(iris$Species = virginica, mean)
lapply(split(iris), mean)
split(iris)
split(iris$Sepal.Length)
s <- split(iris, iris$Species)
lapply(iris, s, mean)
lapply(split(iris, s), mean)
lapply(s, function(iris) mean)
lapply(s, function(iris) colMeans(iris[,c("Petal.Length")]))
s
summary(s)
lapply(s, mean)
lapply(split(iris, s), mean)
lapply(split(iris, iris$Species), mean)
lapply(split(iris, iris$Species[,1]), mean)
lapply(split(iris, iris$Sepal.Length), mean)
lapply(s, mean)
sapply(s, mean)
sapply(iris, mean)
s
sapply(iris, colMeans)
sapply(s, colMeans)
sapply(iris, colMeans)
apply(s$virginica, 1, mean)
apply(s$virginica, 2, mean)
sapply(s$virginica, 2, mean)
colMeans(iris)
rowMeans(iris[, 1:4])
apply(iris[, 1:4], 2, mean)
apply(iris, 2, mean)
tapply(iris, s, mean)
s
tapply(iris$Sepal.Length, Species , mean)
tapply(iris$Sepal.Length, iris$Species , mean)
library(datasets)
data(mtcars)
?mtcars
split(mtcars, mtcars$cyl)
tapply(mtcars$mpg, mtcars$cyl, mean)
sapply(mtcars, cyl, mean)
lapply(mtcars, mean)
View(mtcars)
tapply(mtcars$hp, mtcars$cyl, mean)
x <- tapply(mtcars$hp, mtcars$cyl, mean)
?abs
y <- abs(x([1]-[3]))
y <- x([1]-[3])
y <- x([1])-x([3])
y <- x(,[1])-x(,[3])
y <- x(1-3)
class(x)
y <- x(x[1-3])
y <- (x[1-3])
y <- abs((x[1]-x[3]))
y
x <- tapply(mtcars$hp, mtcars$cyl, mean)
x
y
20921429-8263636
tapply(iris$Sepal.Length, iris$Species , mean)
debug(ls)
ls
exit
exit()
library(swirl)
swirl()
head(flags)
dim(flags)
class(flags)
cls_list <- lapply(flags, class)
cls_list
class(cls_list)
as.character(cls_list)
sapply(flags, class)
cls_vect <- sapply(flags, class)
class(cls_vect)
sum(flags$orange)
flag_colors <- flags[, 11:17]
head(flag_colors)
lapply(flag_colors, sum)
sapply(flag_colors, sum)
sapply(flag_colors, mean)
flag_shapes <- flags[, 19:23]
lapply(flag_shapes, range)
shape_mat <- sapply(flag_shapes, range)
shape_mat
class(shape_mat)
unique(c(3, 4, 5, 5, 5, 6, 6))
unique_vals <- lapply(flags, unique)
unique_vals
sapply(unique_vals, length)
sapply(flags, unique)
lappy(unique_vals, function(elem) elem[2])
lapply(unique_vals, function(elem) elem[2])
sapply(flags, unique)
vapply(flags, unique, numeric(1))
ok()
sapply(flags, class)
vapply(flags, class, character(1))
?tapply
table(flags$landmass)
table(flags$animate)
tapply(flags$animate, flags$landmass, mean)
tapply(flags$population, flags$red, summary)
tapply(flags$population, flags$landmass, summary)
ls()
class(plants)
dim(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
head(plants)
head(plants, 10)
tail(plants, 15)
summary(plants)
table(plants$Active_Growth_Period)
str(plants)
?sample
sample(1:6, 4 replace = TRUE)
ample(1:6, 4, replace = TRUE)
sample(1:6, 4, replace = TRUE)
sample(1:6, 4, replace = TRUE)
sample(1:20, 10)
LETTERS
sample(LETTERS)
flips <- sample(c(0,1), 100, prob = c(0.3, 0.7))
flips <- sample(c(0,1), 100, replace = TRUE, prob = c(0.3, 0.7))
flips
sum(flips)
?rbinom
rbinom(1, size = 100, prob = 0.7)
flips2 <- rbinom(c(0,1), 100, prob = 0.7)
flips2 <- rbinom(100, 1, prob = 0.7)
flips2
sum(heads)
sum(flips2)
?rnorm
rnorm(10)
rnorm(10, 100, 25)
rpois(10)
?rpois
rpois(5, 10)
my_pois <- replicate(100, rpois(5, 10))
py_pois
my_pois
cm <- colMeans(my_pois)
hist(cm)
library(xlsx)
read.xlsx("NGAP.xlsx", sheetIndex=1, header=TRUE)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileUrl, destfile = "NGAP.xlsx", method = "curl")
NGAP <- read.xlsx("NGAP.xlsx", sheetIndex=1, header=TRUE)
dat <- read.xlsx("NGAP.xlsx", sheetIndex=1, colIndex=colIndex, rowIndex=rowIndex)
colIndex <- 7:15
rowIndex <- 18:23
dat <- read.xlsx("NGAP.xlsx", sheetIndex=1, colIndex=colIndex, rowIndex=rowIndex)
sum(dat$Zip*dat$Ext,na.rm=T)
install.packages("XML")
library(XML)
doc <- xmlTreeParse(https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml, useInternal=TRUE)
doc <- xmlTreeParse("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml", useInternal=TRUE)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
doc <- xmlTreeParse(fileUrl, useInternal=TRUE, method = "curl")
fileUrl <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
doc
rootNode <- xmlRoot(doc) # wrapper for entire document
xmlName(rootNode)
names(rootNode)
xpathSApply(rootNode,"//zipcode",xmlValue)
zipcode <- xpathSApply(rootNode,"//zipcode",xmlValue)
summary(zipcode)
table(zipcode)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl, destfile = "housingIdaho2.csv", method = "curl")
install.packages("data.table")
library(data.table)
?"data.table"
?fread
DT <- fread(housingIdaho2.csv)
DT <- fread("housingIdaho2.csv")
summary(DT)
head(DT)
install.packages("RMySQL")
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "afd62a2a79f98b114881",
secret = "64a44fc0ded70083ee8f55217dbcccf6f7f80fdd")
# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
key = "afd62a2a79f98b114881",
secret = "64a44fc0ded70083ee8f55217dbcccf6f7f80fdd")
# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("sweettry"), myapp)
oauth_endpoints("sweettry")
library(httr)
# 1. Find OAuth settings for github:
#    http://developer.github.com/v3/oauth/
oauth_endpoints("sweettry")
# 2. To make your own application, register at at
#    https://github.com/settings/applications. Use any URL for the homepage URL
#    (http://github.com is fine) and  http://localhost:1410 as the callback url
#
#    Replace your key and secret below.
myapp <- oauth_app("sweettry",
key = "afd62a2a79f98b114881",
secret = "64a44fc0ded70083ee8f55217dbcccf6f7f80fdd")
# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("sweettry"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
req <- with_config(gtoken, GET("https://api.github.com/rate_limit"))
stop_for_status(req)
content(req)
install.packages("RMySQL")
doc <- htmlTreeParse("http://biostat.jhsph.edu/~jleek/contact.html", useInternal=TRUE)
library(XML)
doc <- htmlTreeParse("http://biostat.jhsph.edu/~jleek/contact.html", useInternal=TRUE)
doc
library(httr)
html2 = GET("http://biostat.jhsph.edu/~jleek/contact.html")
content2 = content(html2, as="text")
parsedHtml = htmlParse(content2, asText=TRUE)
xpathSApply(parsedHtml, xmlValue)
html2 = GET("http://biostat.jhsph.edu/~jleek/contact.html")
content2 = content(html2, as="text")
parsedHtml = htmlParse(content2, asText=TRUE)
xpathSApply(parsedHtml, "//title", xmlValue)
connection <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode <- readLines(connection)
close(connection)
c(nchar(htmlCode[10]), nchar(htmlCode[20]), nchar(htmlCode[30]), nchar(htmlCode[100]))
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
lines <- readLines(url, n=10)
w <- c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3)
colNames <- c("filler", "week", "filler", "sstNino12", "filler", "sstaNino12", "filler", "sstNino3", "filler", "sstaNino3", "filler", "sstNino34", "filler", "sstaNino34", "filler", "sstNino4", "filler", "sstaNino4")
d <- read.fwf(url, w, header=FALSE, skip=4, col.names=colNames)
d <- d[, grep("^[^filler]", names(d))]
sum(d[, 4])
library(swirl)
install_from_swirl("Exploratory Data Analysis")
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
?trellis.par.set
library(datasets)
data(airquality)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(ggplot2)
install.packages("ggplot2")
library(ggplot2)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
g <- ggplot(movies, aes(votes, rating))
print(g)
R.version.string
swirl()
library(swirl)
swirl()
head(pollution)
dim(pollution)
summary(pollution$pm25)
quantile(ppm)
boxplot(ppm, col = "blue")
abline(h = 12)
hist(ppm, col = "green")
rug(ppm)
low
high
hist(ppm, col = "green", break = 100)
hist(ppm, col = "green", breaks = 100)
rug(ppm)
hist(ppm, col = "green")
abline(v = 12, lwd = 2)
abline(v = median(ppm), col = "magenta", lwd = 4)
names(pollution)
table(pullution$region)
reg <- table(pollution, pollution$region)
reg <- table(pollution$region)
reg
barplot(reg, col = "wheat", main = "Number of Counties in Each Region")
boxplot(pollution, pm25 ~ region, col = "red")
boxplot(pm25 ~ region, data = pollution, col = "red")
par(mfrow=c(2,1),mar=c(4,4,2,1))
east <- subset(pollution, region = "east")
east <- subset(pollution, region == "east")
head(east)
hist(east$pm25, col = "green")
hist(east$pm25, col = "green")
hist(east$pm25, col = "green")
hist(subset(pollution, region == "west), col = "green"))
hist(subset(pollution, region == "west"), col = "green"))
hist(subset(pollution, region == "west"), col = "green")
hist(subset(pollution, region == "west"), col = "green")
?
hist(subset(pollution, region == "west"), col = "green"))
hist(subset(pollution$pm25, region == "west"), col = "green"))
hist(subset(pollution, region == "west")$pm25, col = "green"))
hist([subset(pollution, region == "west",pm25]), col = "green"))
hist(subset(pullution$pm25, region == "west"), col = "green"))
hist(subset(pullution$pm25, region == "west"), col = "green")
hist(subset(pollution$pm25, region == "west"), col = "green")
hist(subset(pollution$pm25, pollution$region == "west"), col = "green")
hist(subset(pollution, pollution == "west")$pm25, col = "green")
hist(subset(pollution, region == "west")$pm25, col = "green")
with(pollution, plot(latitude, pm25))
abline(12, lwd = 2, lty = 2)
abline(v = 12, lwd = 2, lty = 2)
abline(h = 12, lwd = 2, lty = 2)
plot(pollution$latitude, pollution$pm25, col = pollution$region)
plot(pollution$latitude, ppm, col = pollution$region)
abline( h = 12, lwd = 2, lty = 2)
par(mfrow = c(1,2), mar = c(5,4,2,1))
west <- subset(pollution, region == "west")
plot(west$latitude, west$pm25, main = "West")
plot(east$latitude, east$pm25, main = "East")
dist(dataFrame)
hc <- hclust(distxy)
plot(hc)
plot(as.dendrogram(hc))
abline(h 1.5, col = "blue")
abline(h = 1.5, col = "blue")
abline(h = .4, col = "blue")
abline(h = .4, col = "red")
5
5
12
abline(h = .05, col = "green")
dist(dFsm)
hc
heatmap(dataMatrix, col = cm.colors(25))
heatmap(mt)
mt
plot(denmt)
distmt
cmat
points(cx, cy, col = c("red", "orange", "purple"), lwd = 2)
points(cx, cy, col = c("red", "orange", "purple"), pch = 3, cex = 2, lwd = 2)
mdist(x, y, cx, cy)
apply(distTmp, 2, which.min)
points(x, y, pch = 19, cex= 2, col = cols1[newClust])
tapply(xm newClust, mean)
tapply(x, newClust, mean)
tapply(y, newClust, mean)
points(newCx, newCy, col=cols1, pch=8, cex=2, lwd=2)
mdist(x, y, newCx, newCy)
apply(distTmp2, 2, which.min)
points(x, y, pch=19, cex=2, col = cols1[newClust2])
tapply(x, newClust2, mean)
tapply(y, newClust2, mean)
points(finalCx, finalCy, col=cols1, pch=9, cex=2, lwd=2)
kmeans(dataFrame, centers=3)
kmObj$iter
plot(x, y, col=kmObj$cluster, pch=19, cex=2)
points(kmObj$centers, col=c("black", "red", "green"), pch=3,cex=3, lwd=3)
plot(x, y, col=kmeans(dataFrame, 6$cluster), pch=19, cex=2)
plot(x, y, col=kmeans(dataFrame, 6)$cluster, pch=19, cex=2)
plot(x, y, col=kmeans(dataFrame, 6)$cluster, pch=19, cex=2)
plot(x, y, col=kmeans(dataFrame, 6)$cluster, pch=19, cex=2)
head(dataMatrix)
heatmap(dataMatrix)
myedit("addPatt.R")
myedit("addPatt.R", local = TRUE)
source("addPatt.R", local = TRUE)
heatmap(dataMatrix)
mat
svd(mat)
matu %*% diag %*% t(matv)
svd(scale(mat))
prcomp(scale(mat))
svd1$v[,1]
svd1$d
head(constantMatrix)
svd2$d
svd2$v[,1:2]
svd2$d
dim(faceData)
a1 <-
a1 <- (svd1$u[,1] %*% (svd1$d[1] %*% svd1$v
a1 <- (svd1$u[,1] %*% (svd1$d[1] %*% svd1$v
a1 <- (svd1$u[,1]) %*% (svd1$d[1]) %*% svd1$v
a1 <- (svd1$u[,1]) %*% (svd1$d[1]) %*% svd1$v
a1 <- (svd1$u[,1]) %*% (svd1$d[1])
?
exit()
quit()
activity <- read.csv("activity.csv")
setwd("~/Workspace/Coursera/05 Reproducible research/RepData_PeerAssessment1")
activity <- read.csv("activity.csv")
library(dplyr)
activity2 <- activity
for(i in 1:nrow(activity2)) {
if(is.na(activity2$steps[i])) {
missinginterval <- activity2$interval[i]
rowmisinterval <- which(activitymean$interval ==  missinginterval)
meanmisinterval <- activitymean$meansteps[rowmisinterval]
activity2$steps[i] <- meanmisinterval
}
}
activityinterval <- group_by(na.omit(activity), interval)
activitymean <- summarise(activityinterval, meansteps=mean(steps))
activity2 <- activity
for(i in 1:nrow(activity2)) {
if(is.na(activity2$steps[i])) {
missinginterval <- activity2$interval[i]
rowmisinterval <- which(activitymean$interval ==  missinginterval)
meanmisinterval <- activitymean$meansteps[rowmisinterval]
activity2$steps[i] <- meanmisinterval
}
}
activity2date <- group_by(activity2, date)
activity2sum <- summarise(activity2date, sumsteps=sum(steps))
hist(activity2sum$sumsteps,
main="Histogram of sum of steps per day",
xlab="sum of steps per day")
mean(activity2sum$sumsteps)
median(activity2sum$sumsteps)
activity2$date <- as.Date(activity2$date)
activity2$day <- weekdays(activity2$date)
activity2$daytype <- c("weekday")
for(i in 1:nrow(activity2)) {
if (activity2$day[i] == "Saturday" | activity2$day[i] == "Sunday") {
activity2$daytype[i] <- c("weekend")
}
}
activity2$daytype <- as.factor(activity2$daytype)
activity2agg <- aggregate(steps ~ interval * daytype, data = activity2, FUN=mean)
library(ggplot2)
qplot(interval, steps, data = activity2agg, facets = daytype ~ .,
geom = "line",
method = "lm",
main = "Average amount of steps per interval for weekdays and weekends")
par(mfrow=c(2,1))
qplot(interval, steps, data = activity2agg, facets = daytype ~ .,
geom = "line",
method = "lm",
main = "Average amount of steps per interval for weekdays and weekends")
?facets
qplot(interval, steps, data = activity2agg,
facets = . ~ daytype,
geom = "line",
method = "lm",
main = "Average amount of steps per interval for weekdays and weekends")
qplot(interval, steps, data = activity2agg,
facets = . ~ daytype,
geom = c("line"),
method = "lm",
main = "Average amount of steps per interval for weekdays and weekends")
qplot(interval, steps, data = activity2agg,
facet = daytype ~ .,
geom = "line",
method = "lm",
main = "Average amount of steps per interval for weekdays and weekends")
qplot(interval, steps, data = activity2agg,
daytype ~ .,
geom = "line",
method = "lm",
main = "Average amount of steps per interval for weekdays and weekends")
activity2$daytype <- as.factor(activity2$daytype)
activity2agg <- aggregate(steps ~ interval * daytype, data = activity2, FUN=mean)
qplot(interval, steps, data = activity2agg,
facets = daytype ~ .,
geom = "line",
method = "lm",
main = "Average amount of steps per interval for weekdays and weekends")
for(i in 1:nrow(activity2)) {
if (activity2$day[i] == "Saturday" | activity2$day[i] == "Sunday") {
activity2$daytype[i] <- c("weekend")
}
}
activity2$daytype <- as.factor(activity2$daytype)
activity2agg <- aggregate(steps ~ interval * daytype, data = activity2, FUN=mean)
qplot(interval, steps, data = activity2agg,
facets = daytype ~ .,
geom = "line",
method = "lm",
main = "Average amount of steps per interval for weekdays and weekends")
activity <- read.csv("activity.csv")
summary(activity)
head(activity)
plot(activity$date, activity$steps)
plot(activity$interval, activity$steps)
library(dplyr)
activitydate <- group_by(na.omit(activity), date)
activitysum <- summarise(activitydate, sumsteps=sum(steps))
hist(activitysum$sumsteps,
main="Histogram of sum of steps per day",
xlab="sum of steps per day")
mean(activitysum$sumsteps)
median(activitysum$sumsteps)
activityinterval <- group_by(na.omit(activity), interval)
activitymean <- summarise(activityinterval, meansteps=mean(steps))
plot(activitymean$interval, activitymean$meansteps, type="l",
main="Average steps per interval",
xlab="interval",
ylab="average steps")
